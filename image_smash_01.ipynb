{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from sys import stderr\n",
    "from functools import reduce\n",
    "import time  \n",
    "import tensorflow as tf\n",
    "\n",
    "## image inputs \n",
    "file_content_image = 'wavetree.jpg' \n",
    "file_style_image = 'wall_pic copy.jpg'   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c6187702dc8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conv1_1'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0m_conv2d_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'conv1_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conv1_2'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0m_conv2d_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conv1_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'conv1_2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avgpool1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_avgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conv1_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-c6187702dc8f>\u001b[0m in \u001b[0;36m_conv2d_relu\u001b[0;34m(prev_layer, n_layer, layer_name)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG19_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;31m# create a conv2d layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mconv2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "## Parameters \n",
    "input_noise = 0.1     # proportion noise to apply to content image\n",
    "weight_style = 2e2 \n",
    "\n",
    "## Layers\n",
    "layer_content = 'conv4_2' \n",
    "layers_style = ['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']\n",
    "layers_style_weights = [0.2,0.2,0.2,0.2,0.2]\n",
    "\n",
    "## VGG19 model\n",
    "path_VGG19 = 'imagenet-vgg-verydeep-19.mat'\n",
    "# VGG19 mean for standardisation (RGB)\n",
    "VGG19_mean = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n",
    "\n",
    "## Reporting & writing checkpoint images\n",
    "# NB. the total # of iterations run will be n_checkpoints * n_iterations_checkpoint\n",
    "n_checkpoints = 10            # number of checkpoints\n",
    "n_iterations_checkpoint = 10   # learning iterations per checkpoint\n",
    "path_output = 'output'  # directory to write checkpoint images into\n",
    "\n",
    "\n",
    "### Helper functions\n",
    "def imread(path):\n",
    "    return scipy.misc.imread(path).astype(np.float)   # returns RGB format\n",
    "def imsave(path, img):\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    scipy.misc.imsave(path, img)\n",
    "def imgpreprocess(image):\n",
    "    image = image[np.newaxis,:,:,:]\n",
    "    return image - VGG19_mean\n",
    "def imgunprocess(image):\n",
    "    temp = image + VGG19_mean\n",
    "    return temp[0] \n",
    "\n",
    "# function to convert 2D greyscale to 3D RGB\n",
    "def to_rgb(im):\n",
    "    w, h = im.shape\n",
    "    ret = np.empty((w, h, 3), dtype=np.uint8)\n",
    "    ret[:, :, 0] = im\n",
    "    ret[:, :, 1] = im\n",
    "    ret[:, :, 2] = im\n",
    "    return ret\n",
    " \n",
    "### Preprocessing\n",
    "# create output directory\n",
    "if not os.path.exists(path_output):\n",
    "    os.mkdir(path_output)\n",
    "\n",
    "# read in images\n",
    "img_content = imread(file_content_image) \n",
    "img_style = imread(file_style_image) \n",
    "\n",
    "# convert if greyscale\n",
    "if len(img_content.shape)==2:\n",
    "    img_content = to_rgb(img_content)\n",
    "if len(img_style.shape)==2:\n",
    "    img_style = to_rgb(img_style)\n",
    "\n",
    "# resize style image to match content\n",
    "img_style = scipy.misc.imresize(img_style, img_content.shape)\n",
    "\n",
    "# apply noise to create initial \"canvas\" \n",
    "noise = np.random.uniform(\n",
    "        img_content.mean()-img_content.std(), img_content.mean()+img_content.std(),\n",
    "        (img_content.shape)).astype('float32')\n",
    "img_initial = noise * input_noise + img_content * (1 - input_noise)\n",
    "\n",
    "# preprocess each\n",
    "img_content = imgpreprocess(img_content)\n",
    "img_style = imgpreprocess(img_style)\n",
    "img_initial = imgpreprocess(img_initial)\n",
    "  \n",
    "#### BUILD VGG19 MODEL\n",
    "## with thanks to http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style\n",
    "VGG19 = scipy.io.loadmat(path_VGG19)\n",
    "VGG19_layers = VGG19['layers'][0]\n",
    "\n",
    "# help functions\n",
    "def _conv2d_relu(prev_layer, n_layer, layer_name):\n",
    "    # get weights for this layer:\n",
    "    weights = VGG19_layers[n_layer][0][0][2][0][0]\n",
    "    W = tf.constant(weights)\n",
    "    bias = VGG19_layers[n_layer][0][0][2][0][1]\n",
    "    b = tf.constant(np.reshape(bias, (bias.size)))\n",
    "    # create a conv2d layer\n",
    "    conv2d = tf.nn.conv2d(prev_layer, filter=W, strides=[1, 1, 1, 1], padding='SAME') + b    \n",
    "    # add a ReLU function and return\n",
    "    return tf.nn.relu(conv2d)\n",
    "def _avgpool(prev_layer):\n",
    "    return tf.nn.avg_pool(prev_layer, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# Setup network\n",
    "with tf.Session() as sess:\n",
    "    a, h, w, d = img_content.shape\n",
    "    net = {}\n",
    "    net['input']   = tf.Variable(np.zeros((a, h, w, d), dtype=np.float32))\n",
    "    net['conv1_1']  = _conv2d_relu(net['input'], 0, 'conv1_1')\n",
    "    net['conv1_2']  = _conv2d_relu(net['conv1_1'], 2, 'conv1_2')\n",
    "    net['avgpool1'] = _avgpool(net['conv1_2'])\n",
    "    net['conv2_1']  = _conv2d_relu(net['avgpool1'], 5, 'conv2_1')\n",
    "    net['conv2_2']  = _conv2d_relu(net['conv2_1'], 7, 'conv2_2')\n",
    "    net['avgpool2'] = _avgpool(net['conv2_2'])\n",
    "    net['conv3_1']  = _conv2d_relu(net['avgpool2'], 10, 'conv3_1')\n",
    "    net['conv3_2']  = _conv2d_relu(net['conv3_1'], 12, 'conv3_2')\n",
    "    net['conv3_3']  = _conv2d_relu(net['conv3_2'], 14, 'conv3_3')\n",
    "    net['conv3_4']  = _conv2d_relu(net['conv3_3'], 16, 'conv3_4')\n",
    "    net['avgpool3'] = _avgpool(net['conv3_4'])\n",
    "    net['conv4_1']  = _conv2d_relu(net['avgpool3'], 19, 'conv4_1')\n",
    "    net['conv4_2']  = _conv2d_relu(net['conv4_1'], 21, 'conv4_2')     \n",
    "    net['conv4_3']  = _conv2d_relu(net['conv4_2'], 23, 'conv4_3')\n",
    "    net['conv4_4']  = _conv2d_relu(net['conv4_3'], 25, 'conv4_4')\n",
    "    net['avgpool4'] = _avgpool(net['conv4_4'])\n",
    "    net['conv5_1']  = _conv2d_relu(net['avgpool4'], 28, 'conv5_1')\n",
    "    net['conv5_2']  = _conv2d_relu(net['conv5_1'], 30, 'conv5_2')\n",
    "    net['conv5_3']  = _conv2d_relu(net['conv5_2'], 32, 'conv5_3')\n",
    "    net['conv5_4']  = _conv2d_relu(net['conv5_3'], 34, 'conv5_4')\n",
    "    net['avgpool5'] = _avgpool(net['conv5_4'])\n",
    "\n",
    "\n",
    "### CONTENT LOSS: FUNCTION TO CALCULATE AND INSTANTIATION\n",
    "# with thanks to https://github.com/cysmith/neural-style-tf\n",
    "# Recode to be simpler: http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style\n",
    "def content_layer_loss(p, x):\n",
    "    _, h, w, d = [i.value for i in p.get_shape()]    # d: number of filters; h,w : height, width\n",
    "    M = h * w \n",
    "    N = d \n",
    "    K = 1. / (2. * N**0.5 * M**0.5)\n",
    "    loss = K * tf.reduce_sum(tf.pow((x - p), 2))\n",
    "    return loss\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(net['input'].assign(img_content))\n",
    "    p = sess.run(net[layer_content])  # Get activation output for content layer\n",
    "    x = net[layer_content]\n",
    "    p = tf.convert_to_tensor(p)\n",
    "    content_loss = content_layer_loss(p, x) \n",
    "\n",
    "\n",
    "### STYLE LOSS: FUNCTION TO CALCULATE AND INSTANTIATION\n",
    "def style_layer_loss(a, x):\n",
    "    _, h, w, d = [i.value for i in a.get_shape()]\n",
    "    M = h * w \n",
    "    N = d \n",
    "    A = gram_matrix(a, M, N)\n",
    "    G = gram_matrix(x, M, N)\n",
    "    loss = (1./(4 * N**2 * M**2)) * tf.reduce_sum(tf.pow((G - A), 2))\n",
    "    return loss\n",
    "def gram_matrix(x, M, N):\n",
    "    F = tf.reshape(x, (M, N))                   \n",
    "    G = tf.matmul(tf.transpose(F), F)\n",
    "    return G\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(net['input'].assign(img_style))\n",
    "    style_loss = 0.\n",
    "    # style loss is calculated for each style layer and summed\n",
    "    for layer, weight in zip(layers_style, layers_style_weights):\n",
    "        a = sess.run(net[layer])\n",
    "        x = net[layer]\n",
    "        a = tf.convert_to_tensor(a)\n",
    "        style_loss += style_layer_loss(a, x)\n",
    "        \n",
    "### Define loss function and minimise\n",
    "with tf.Session() as sess:\n",
    "    # loss function\n",
    "    L_total  = content_loss + weight_style * style_loss \n",
    "    \n",
    "    # instantiate optimiser\n",
    "    optimizer = tf.contrib.opt.ScipyOptimizerInterface(\n",
    "      L_total, method='L-BFGS-B',\n",
    "      options={'maxiter': n_iterations_checkpoint})\n",
    "    \n",
    "    init_op = tf.initialize_all_variables()\n",
    "    sess.run(init_op)\n",
    "    sess.run(net['input'].assign(img_initial))\n",
    "    for i in range(1,n_checkpoints+1):\n",
    "        # run optimisation\n",
    "        optimizer.minimize(sess)\n",
    "        \n",
    "        ## print costs\n",
    "        stderr.write('Iteration %d/%d\\n' % (i*n_iterations_checkpoint, n_checkpoints*n_iterations_checkpoint))\n",
    "        stderr.write('  content loss: %g\\n' % sess.run(content_loss))\n",
    "        stderr.write('    style loss: %g\\n' % sess.run(weight_style * style_loss))\n",
    "        stderr.write('    total loss: %g\\n' % sess.run(L_total))\n",
    "\n",
    "        ## write image\n",
    "        img_output = sess.run(net['input'])\n",
    "        img_output = imgunprocess(img_output)\n",
    "        timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_file = path_output+'/'+timestr+'_'+'%s.jpg' % (i*n_iterations_checkpoint)\n",
    "        imsave(output_file, img_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
